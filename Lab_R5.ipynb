{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diego-ascenciorod/Clase-Laboratorio-Estadistico/blob/main/Lab_R5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70086771-ad90-497d-9b51-22626c9cce63",
      "metadata": {
        "id": "70086771-ad90-497d-9b51-22626c9cce63"
      },
      "source": [
        "# Laboratorio de regresión - 5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f666e0e-9e63-49f4-96e1-053c5b1738c3",
      "metadata": {
        "id": "9f666e0e-9e63-49f4-96e1-053c5b1738c3"
      },
      "source": [
        "|                |   |\n",
        ":----------------|---|\n",
        "| **Nombre**     |  Diego Ascencio Rodriguez |\n",
        "| **Fecha**      |  16-02-2026 |\n",
        "| **Expediente** |  755690 |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19f352dc-5863-4685-af3c-25f8fcf60841",
      "metadata": {
        "id": "19f352dc-5863-4685-af3c-25f8fcf60841"
      },
      "source": [
        "## Validación"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WRqfsdBWx_ed"
      },
      "id": "WRqfsdBWx_ed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b73fccec-9651-4f74-9d56-a3c2b2097e19",
      "metadata": {
        "id": "b73fccec-9651-4f74-9d56-a3c2b2097e19"
      },
      "source": [
        "Hemos estado usando `train_test_split` en nuestros modelos anteriores.\n",
        "\n",
        "¿Por qué?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84fe97ab-a033-4d0f-ab73-0cdabe591655",
      "metadata": {
        "id": "84fe97ab-a033-4d0f-ab73-0cdabe591655"
      },
      "source": [
        "Lo usamos porque necesitamos evaluar la capacidad de generalización del modelo, qué tan bien funciona con datos que no ha visto antes, si lo entrenamos y evaluamos con los mismos datos solo medimos el error de entrenamiento que suele ser más bajo y puede dar un falso buen desempeño debido al overfitting, al separar los datos en entrenamiento y prueba podemos estimar el error fuera de muestra y obtener una medida más realista del desempeño del modelo en situaciones reales."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a60a028-ed60-4a5c-9308-dee4862e2bac",
      "metadata": {
        "id": "0a60a028-ed60-4a5c-9308-dee4862e2bac"
      },
      "source": [
        "Si la muestra es un subset de la población y queremos generalizar sobre la población, ¿no sería mejor utilizar todos los datos al entrenar un modelo?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50989a32-59e7-4bef-9b60-89f543d8ca81",
      "metadata": {
        "id": "50989a32-59e7-4bef-9b60-89f543d8ca81"
      },
      "source": [
        "Aunque la muestra ya representa una parte de la población no nos conviene usar todos los datos desde el inicio porque perderíamos la posibilidad de validar objetivamente el modelo, necesitamos reservar una parte para prueba para estimar cómo se comportará frente a datos nuevos, pero si usamos todo para entrenar no podemos medir el error fuera de muestra y el desempeño estimado estaría sesgado, una vez que seleccionamos y validamos el mejor modelo entonces sí podemos entrenarlo con todos los datos disponibles para su versión final."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b98d96f3-7370-4161-aa67-75f10e5817cd",
      "metadata": {
        "id": "b98d96f3-7370-4161-aa67-75f10e5817cd"
      },
      "source": [
        "El propósito de volver a muestrear dentro de nuestro dataset es tener una idea de qué tan buena podría ser la generalización de nuestro modelo. Imagina un dataset ya separado en dos mitades. Utilizas la primera mitad para entrenar el modelo y pruebas en la segunda mitad; la segunda mitad eran datos invisibles para el modelo al momento de entrenar. Esto nos lleva a tres escenario típicos:\n",
        "\n",
        "1. Si el modelo hace buenas predicciones en la segunda mitad, significa que la primera mitad era \"suficiente\" para generalizar.\n",
        "2. Si el modelo no hace buenas predicciones en la segunda mitad, pero sí en la primera mitad, podría ser que había información importante en la segunda mitad que debió haber sido tomada en cuenta al entrenar, o un problema de overfitting.\n",
        "3. Si el modelo no hace buenas predicciones en la segunda mitad, y tampoco en la primera mitad, se tendrían que revisar los factores y/o el modelo seleccionado.\n",
        "\n",
        "El caso ideal sería el 1, pero por estadística los errores y varianzas tienen como entrada el número de muestas, por lo que tenemos menos seguridad de nuestros resutados al usar menos muestras. Si vemos que el modelo generaliza bien podemos unir de nuevo el dataset y entrenar sobre el dataset completo.\n",
        "\n",
        "En el caso 2 está el problema de que no podemos saber qué información es necesaria para el entrenamiento apropiado del modelo; esto nos lleva a pensar que debemos usar el dataset completo para entrenar, pero esto nos lleva al mismo problema de no saber si el modelo puede generalizar.\n",
        "\n",
        "El problema sólo incrementa si se tienen hiperparámetros en el modelo (e.g. $\\lambda$ en regularización)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a16176ad-41fc-4f3c-b865-2eb4219152e2",
      "metadata": {
        "id": "a16176ad-41fc-4f3c-b865-2eb4219152e2"
      },
      "source": [
        "## Leave-One-Out Cross Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1f7165d-5b5d-4e92-ae7f-7edb12eea745",
      "metadata": {
        "id": "e1f7165d-5b5d-4e92-ae7f-7edb12eea745"
      },
      "source": [
        "Este método de validación es una colección de $n$ `train-test-split`. Teniendo un dataset de $n$ muestras, la lógica es:\n",
        "1. Saca una muestra del dataset.\n",
        "2. Entrena tu modelo con las $n-1$ muestras.\n",
        "3. Evalúa tu modelo en la muestra que quedó fuera con el métrico que más se ajuste a la aplicación.\n",
        "4. Regresa la muestra al dataset.\n",
        "5. Repite 1-4 con muestras diferentes hasta haber hecho el procedimiento $n$ veces para $n$ muestras.\n",
        "6. Calcula la media y desviación estándar de los métricos guardados."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21340b80-8fa4-4cdf-8fe4-85e4a35febcd",
      "metadata": {
        "id": "21340b80-8fa4-4cdf-8fe4-85e4a35febcd"
      },
      "source": [
        "Con los resultados del proceso de validación podemos saber qué tan bueno podría ser el modelo seleccionado con los datos (con/sin transformaciones)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0983bf1c-a6a2-42e4-a522-92bba6b450ab",
      "metadata": {
        "id": "0983bf1c-a6a2-42e4-a522-92bba6b450ab"
      },
      "source": [
        "### Ejercicio 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21e5f076-bc52-482c-9560-ecd0c125efa7",
      "metadata": {
        "id": "21e5f076-bc52-482c-9560-ecd0c125efa7"
      },
      "source": [
        "Utiliza el dataset `Motor Trend Car Road Tests`. Elimina la columna `model` y entrena 32 modelos diferentes utilizando Leave-One-Out Cross Validation con target `mpg`. Utiliza MSE como métrico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "89510da9-15a9-41e5-bd0e-855291acec2a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "89510da9-15a9-41e5-bd0e-855291acec2a",
        "outputId": "509fe538-f134-4111-de34-0e811dc444a9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1ac9ad88-6d76-45c1-a9cf-7018cb4ea9d5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1ac9ad88-6d76-45c1-a9cf-7018cb4ea9d5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Motor Trend Car Road Tests (1).xlsx to Motor Trend Car Road Tests (1).xlsx\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b7199ca1-32f0-463b-925f-76613d608a72",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7199ca1-32f0-463b-925f-76613d608a72",
        "outputId": "15053fb4-3c6b-4e4b-9f80-d468d5dc4abe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "columnas del dataset:\n",
            "Index(['model', 'mpg', 'cyl', 'disp', 'hp', 'drat', 'wt', 'qsec', 'vs', 'am',\n",
            "       'gear', 'carb'],\n",
            "      dtype='object')\n",
            "numero de modelos entrenados: 32\n",
            "mse promedio loocv: 12.1816\n",
            "desviacion estandar del mse: 17.0674\n"
          ]
        }
      ],
      "source": [
        "# importar librerías\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# cargar dataset\n",
        "df = pd.read_excel(\"Motor Trend Car Road Tests (1).xlsx\")\n",
        "\n",
        "# verificar columnas\n",
        "print(\"columnas del dataset:\")\n",
        "print(df.columns)\n",
        "\n",
        "# eliminar columna model\n",
        "df = df.drop(columns=[\"model\"])\n",
        "\n",
        "# definir variables\n",
        "X = df.drop(columns=[\"mpg\"])\n",
        "y = df[\"mpg\"]\n",
        "\n",
        "# leave one out\n",
        "loo = LeaveOneOut()\n",
        "model = LinearRegression()\n",
        "\n",
        "# entrenamiento loocv\n",
        "mse_list = []\n",
        "\n",
        "for train_index, test_index in loo.split(X):\n",
        "\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mse_list.append(mse)\n",
        "\n",
        "# resultados\n",
        "mse_mean = np.mean(mse_list)\n",
        "mse_std = np.std(mse_list)\n",
        "\n",
        "print(\"numero de modelos entrenados:\", len(mse_list))\n",
        "print(\"mse promedio loocv:\", round(mse_mean, 4))\n",
        "print(\"desviacion estandar del mse:\", round(mse_std, 4))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8724bdb-e50b-4470-b53a-2d9843fae6ea",
      "metadata": {
        "id": "c8724bdb-e50b-4470-b53a-2d9843fae6ea"
      },
      "source": [
        "Interpreta."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b19904df-1fe6-433a-b1bd-a7ce86ce0eef",
      "metadata": {
        "id": "b19904df-1fe6-433a-b1bd-a7ce86ce0eef"
      },
      "source": [
        "El ejercicio mide qué tan bien generaliza el modelo fuera de muestra, al ser un error cuadrático penaliza predicciones muy alejadas del valor real, aparte la desviación estándar del MSE indica qué tan variable es ese error entre las 32 iteraciones reflejando la sensibilidad del modelo a pequeños cambios en los datos de entrenamiento, si esta es relativamente alta significa que el desempeño del modelo depende bastante de qué observación se deja fuera,} lo cual es característico del LOOCV ya que reduce sesgo pero puede aumentar la varianza del estimador del error."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbc61dd1-fa5f-43b0-969a-592f8e9fc56f",
      "metadata": {
        "id": "dbc61dd1-fa5f-43b0-969a-592f8e9fc56f"
      },
      "source": [
        "## K-Folds Cross-Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dbca526-2c69-4c70-b6b4-270fc51d825b",
      "metadata": {
        "id": "2dbca526-2c69-4c70-b6b4-270fc51d825b"
      },
      "source": [
        "El dataset `Motor Trend Car Road Tests` sólo tiene 32 muestras, y utilizar un modelo sencillo de regresión múltiple hace que usar LOOCV sea muy rápido. El dataset `California Housing` tiene $20640$ muestras para $9$ columnas, entonces realizar un ajuste sobre una transformación o sobre el modelo y luego calcular el impacto esperado podría tomar más tiempo."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a437812-c00e-400f-ae7d-110b3afa5dc3",
      "metadata": {
        "id": "8a437812-c00e-400f-ae7d-110b3afa5dc3"
      },
      "source": [
        "La solución propuesta es dividir el dataset en *k* folds (partes iguales), ajustar en *k-1* folds y probar en el restante."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bb82cc3-0d35-442a-a12b-f9c6fd131af2",
      "metadata": {
        "id": "5bb82cc3-0d35-442a-a12b-f9c6fd131af2"
      },
      "source": [
        "### Ejercicio 2\n",
        "Utiliza el dataset `California Housing` y haz K-folds Cross Validation con 10 folds. Utiliza el MSE como métrico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba50e361-edcd-4cdb-9609-68f20d6fca97",
      "metadata": {
        "id": "ba50e361-edcd-4cdb-9609-68f20d6fca97"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "print(\"Dataset Shape:\", housing.data.shape, housing.target.shape)\n",
        "print(\"Dataset Features:\", housing.feature_names)\n",
        "print(\"Dataset Target:\", housing.target_names)\n",
        "X = housing.data\n",
        "y = housing.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e8570a4-76bb-4d81-a90b-43647b0df438",
      "metadata": {
        "id": "4e8570a4-76bb-4d81-a90b-43647b0df438"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54f44358-f47d-493b-93cf-10aa2314fa20",
      "metadata": {
        "id": "54f44358-f47d-493b-93cf-10aa2314fa20"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "34f7098f-a1de-4508-b3ff-af1484561856",
      "metadata": {
        "id": "34f7098f-a1de-4508-b3ff-af1484561856"
      },
      "source": [
        "Interpreta."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7fbaf4d-f62b-46d9-9a35-23fcdd50a8ca",
      "metadata": {
        "id": "b7fbaf4d-f62b-46d9-9a35-23fcdd50a8ca"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "333c8039-5b38-4835-a523-d4f6f7a7040b",
      "metadata": {
        "id": "333c8039-5b38-4835-a523-d4f6f7a7040b"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "da5792ac-6d38-4f02-bf10-aeaa0a040d17",
      "metadata": {
        "id": "da5792ac-6d38-4f02-bf10-aeaa0a040d17"
      },
      "source": [
        "## Referencia\n",
        "\n",
        "James, G., Witten, D., Hastie, T., Tibshirani, R.,, Taylor, J. (2023). An Introduction to Statistical Learning with Applications in Python. Cham: Springer. ISBN: 978-3-031-38746-3"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}